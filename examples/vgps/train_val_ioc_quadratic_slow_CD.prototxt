name: "JointAndImageStateRegressionNet"
layer {
  # Input is NxTxF
  name: "data_in_demos"
  type: "MemoryData"
  top: "demos"
  top: "dlogis"
  memory_data_param {
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 100  # T
      dim: 26  # dimension of phi
      dim: 1
    }
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 1
      dim: 1
      dim: 1
    }
  }
  include: {phase: TRAIN}
}
layer {
  name: "data_in_samples"
  type: "MemoryData"
  top: "samples"
  top: "slogis"
  memory_data_param {
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 100  # T
      dim: 26  # dimension of phi
      dim: 1
    }
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 1
      dim: 1
      dim: 1
    }
  }
  include: {phase: TRAIN}
}
#layer {
#  name: "data"
#  type: "HDF5Data"
#  top: "demos"
#  hdf5_data_param {
#    source: "examples/vgps/demos_ioc.txt"
#    batch_size: 5  # Must be same as slice point
#  }
#  include: { phase: TRAIN }
#}
#layer {
#  name: "data"
#  type: "HDF5Data"
#  top: "samples"
#  top: "rgb_frames"
#  hdf5_data_param {
#    source: "examples/vgps/samples_ioc.txt"
#    batch_size: 10
#  }
#  include: { phase: TRAIN }
#}
#layer {
#  name: "data"
#  type: "HDF5Data"
#  top: "position"
#  top: "rgb_frames"
#  hdf5_data_param {
#    source: "examples/vgps/train_pose.txt"
#    batch_size: 10
#  }
#  include: {
#    phase: TEST
#    stage: 'test-on-train'
#  }
#}

layer {
  name: "demo_sample_concat"
  type: "Concat"
  bottom: "demos"
  bottom: "samples"
  top: "all_traj"
  concat_param {
    axis: 0
  }
}

layer {
  name: "fc_enc1"
  type: "InnerProduct"
  bottom: "all_traj"
  top: "Ax"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 26 # dimension of phi
    axis: 2  # Input is NxTxF
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "dotproduct1"
  type: "Eltwise"
  bottom: "Ax"
  bottom: "Ax"
  top: "AxAx"
  eltwise_param {
    operation: PROD
  }
}

layer {
  name: "fc_sum"
  type: "InnerProduct"
  bottom: "AxAx"
  top: "all_cost"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1  # Output is cost for every time step - NxT
    axis: 2  # Input is NxTxF
    weight_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "demo_sample_slice"
  type: "Slice"
  bottom: "all_cost"
  top: "demo_cost"
  top: "sample_cost"
  slice_param {
    axis: 0
    slice_point: 5 # Needs to be equal to demo batch size.
  }
}

# Regularization Loss

## Make an input of all zeros
layer {
  name: "zeros"
  type: "Power"
  bottom: "Ax"
  top: "zeros"
  power_param {
    scale: 0
    power: 1
    shift: 0
  }
}

# Slowness loss handling, input NxTx1
layer {
  name: "demo-1_slice"
  type: "Slice"
  bottom: "all_cost"
  top: "t-1_cost"
  top: "end_cost"
  slice_param {
    axis: 1
    slice_point: 98
  }
}
layer {
  name: "demo+1_slice"
  type: "Slice"
  bottom: "all_cost"
  top: "start_cost"
  top: "t+1_cost"
  slice_param {
    axis: 1
    slice_point: 2
  }
}
layer {
  name: "demo+0_slice"
  type: "Slice"
  bottom: "all_cost"
  top: "start_cost1"
  top: "t+0_cost"
  top: "end_cost1"
  slice_param {
    axis: 1
    slice_point: 1
    slice_point: 99
  }
}

layer {
  name: "demo_t+1-demo_t"
  type: "Eltwise"
  bottom: "t+1_cost"
  bottom: "t+0_cost"
  top: "cost_diff1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: -1
  }
}
layer {
  name: "demo_t-demo_t-1"
  type: "Eltwise"
  bottom: "t+0_cost"
  bottom: "t-1_cost"
  top: "cost_diff-1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: -1
  }
}
layer {
  name: "slow_l2_reg_loss"
  type: "EuclideanLoss"
  bottom: "cost_diff1"
  bottom: "cost_diff-1"
  top: "slow_l2_loss"
  loss_weight: 0.1 # 0.1
}
layer {
  name: "silence_layer"
  type: "Silence"
  bottom: "start_cost"
  bottom: "end_cost"
  bottom: "start_cost1"
  bottom: "end_cost1"
}



layer {
  name: "reg_loss"
  type: "EuclideanLoss"
  bottom: "Ax"
  bottom: "zeros"
  top: "reg_loss"
  loss_weight: 1e-4 #1e-6
}
layer {
  name: "demo-sample"
  type: "Eltwise"
  bottom: "demo_cost"
  bottom: "sample_cost"
  top: "obj"
  eltwise_param {
    operation: SUM
    coeff: 1 # Assuming that there are equal number of demos and samples
    coeff: -1
  }
}
layer {
  name: "CDloss"
  type: "SumLoss"
  bottom: "obj"
  top: "cd_gradcomp"
  loss_weight: 1.0
}


layer {
  name: "loss"
  type: "IOCLoss"
  bottom: "demo_cost"
  bottom: "sample_cost"
  bottom: "dlogis"
  bottom: "slogis"
  top: "ioc_loss"
  loss_weight: 0.0 # Used 1 for most things, needs to be more for subsampled
}
