name: "JointAndImageStateRegressionNet"
layer {
  # Input is NxTxF
  name: "data_in_demos"
  type: "MemoryData"
  top: "demos"
  top: "dlogis"
  top: "dU"
  memory_data_param {
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 100  # T
      dim: 32  # dimension of phi
      dim: 1
    }
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 1
      dim: 1
      dim: 1
    }
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 100  # T
      dim: 1
      dim: 1
    }
  }
  include: {phase: TRAIN}
}
layer {
  name: "data_in_samples"
  type: "MemoryData"
  top: "samples"
  top: "slogis"
  top: "sU"
  memory_data_param {
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 100  # T
      dim: 32  # dimension of phi
      dim: 1
    }
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 1
      dim: 1
      dim: 1
    }
    input_shapes {
      dim: 5  # batch size, must be same as slice point
      dim: 100  # T
      dim: 1
      dim: 1
    }
  }
  include: {phase: TRAIN}
}
layer {
  name: "dummy_data_u"
  type: "DummyData"
  top: "dummy_u"
  dummy_data_param {
    shape {
        dim: 10
        dim: 100
        dim: 1
        dim: 1
    }
    data_filler {
        type: "constant"
        value: 1
    }
  }
}
layer {
  name: "demo_sample_concat"
  type: "Concat"
  bottom: "demos"
  bottom: "samples"
  top: "all_traj"
  concat_param {
    axis: 0
  }
}
layer {
  name: "demo_sample_concat"
  type: "Concat"
  bottom: "dU"
  bottom: "sU"
  top: "allU"
  concat_param {
    axis: 0
  }
}
layer {
  name: "allU_reshape"
  type: "Reshape"
  bottom: "allU"
  top: "allU_reshape"
  reshape_param {
    shape {
      dim: 10 # dependent on batch size
      dim: 100
      dim: 1
    }
  }
}
layer {
  name: "fc_enc1"
  type: "InnerProduct"
  bottom: "all_traj"
  top: "enc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    axis: 2  # Input is NxTxF
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "enc1"
  top: "enc1"
}
#layer {
#  name: "drop1"
#  type: "Dropout"
#  bottom: "enc1"
#  top: "enc1"
#  dropout_param {
#  dropout_ratio: 0.2
#  }
#}

layer {
  name: "fc_enc2"
  type: "InnerProduct"
  bottom: "enc1"
  top: "enc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    axis: 2  # Input is NxTxF
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "enc2"
  top: "enc2"
}
#layer {
#  name: "drop1"
#  type: "Dropout"
#  bottom: "enc2"
#  top: "enc2"
#  dropout_param {
#  dropout_ratio: 0.2
#  }
#}
layer {
  name: "fc_enc3"
  type: "InnerProduct"
  bottom: "enc2"
  top: "enc_all"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    axis: 2  # Input is NxTxF
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "enc_all"
  top: "Ax"
  param {
    lr_mult: 1 # 1 for full cold start
    decay_mult: 1
  }
  param {
    lr_mult: 2 # 2 for full cold start
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    axis: 2  # Input is NxTxF
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "dotproduct1"
  type: "Eltwise"
  bottom: "Ax"
  bottom: "Ax"
  top: "AxAx"
  eltwise_param {
    operation: PROD
  }
}

layer {
  name: "fc_sum"
  type: "InnerProduct"
  bottom: "AxAx"
  top: "all_cost"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1  # Output is cost for every time step - NxT
    axis: 2  # Input is NxTxF
    weight_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


# Slowness loss handling, input NxTx1
layer {
  name: "demo-1_slice"
  type: "Slice"
  bottom: "all_cost"
  top: "t-1_cost"
  top: "end_cost"
  slice_param {
    axis: 1
    slice_point: 98
  }
}
layer {
  name: "demo+1_slice"
  type: "Slice"
  bottom: "all_cost"
  top: "start_cost"
  top: "t+1_cost"
  slice_param {
    axis: 1
    slice_point: 2
  }
}
layer {
  name: "demo+0_slice"
  type: "Slice"
  bottom: "all_cost"
  top: "start_cost1"
  top: "t+0_cost"
  top: "end_cost1"
  slice_param {
    axis: 1
    slice_point: 1
    slice_point: 99
  }
}

layer {
  name: "demo_t+1-demo_t"
  type: "Eltwise"
  bottom: "t+1_cost"
  bottom: "t+0_cost"
  top: "cost_diff1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: -1
  }
}
layer {
  name: "demo_t-demo_t-1"
  type: "Eltwise"
  bottom: "t+0_cost"
  bottom: "t-1_cost"
  top: "cost_diff-1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: -1
  }
}
#layer {
#  name: "inv_demo_0"
#  type: "Power"
#  bottom: "demo+0_cost"
#  top: "demo+0_cost_inv"
#  power_param {
#    power: -1
#    shift: 0.1
#  }
#}
#layer {
#  name: "demo_t+1-demo_t"
#  type: "Eltwise"
#  bottom: "demo_cost_diff1"
#  bottom: "demo+0_cost_inv"
#  top: "demo_cost_diff1"
#  eltwise_param {
#    operation: PROD
#  }
#}
#layer {
#  name: "demo_t+1-demo_t"
#  type: "Eltwise"
#  bottom: "demo_cost_diff-1"
#  bottom: "demo+0_cost_inv"
#  top: "demo_cost_diff-1"
#  eltwise_param {
#    operation: PROD
#  }
#}

#layer {
#  name: "slow_l1_reg_loss"
#  type: "L1Loss"
#  bottom: "cost_diff1"
#  bottom: "cost_diff-1"
#  top: "slow_l1_loss"
#  loss_weight: 0
#}
layer {
  name: "slow_l2_reg_loss"
  type: "EuclideanLoss"
  bottom: "cost_diff1"
  bottom: "cost_diff-1"
  top: "slow_l2_loss"
  loss_weight: 0.1 # 0.1
}
layer {
  name: "demo_sample_diffslice"
  type: "Slice"
  bottom: "cost_diff1"
  top: "demo_costdiff"
  top: "sample_costdiff"
  slice_param {
    axis: 0
    slice_point: 5 # Needs to be equal to demo batch size.
  }
}
layer {
  name: "reshape_costdiff"
  type: "Reshape"
  bottom: "demo_costdiff"
  top: "demo_costdiff_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 1
      dim: 0
    }
  }
}
layer {
  name: "silence_layer"
  type: "Silence"
  bottom: "start_cost"
  bottom: "end_cost"
  bottom: "start_cost1"
  bottom: "end_cost1"
  bottom: "sample_costdiff"
}
layer {
  name: "monotonic_loss"
  type: "HingeLoss"
  bottom: "demo_costdiff_reshape"
  top: "monotonic_loss"
  hinge_loss_param {
    norm: L2
  }
  loss_weight: 1.0 #0.0000000001
}
# Regularization Loss

## Make an input of all zeros
layer {
  name: "zeros"
  type: "Power"
  bottom: "Ax"
  top: "zeros"
  power_param {
    scale: 0
    power: 1
    shift: 0
  }
}
layer {
  name: "reg_loss"
  type: "EuclideanLoss"
  bottom: "Ax"
  bottom: "zeros"
  top: "reg_loss"
  loss_weight: 0 #1e-4
}

layer {
  name: "torque_penalty"
  type: "InnerProduct"
  bottom: "dummy_u"
  top: "torque_weight"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    axis: 2  # Input and output are NxTx1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "torqueweight^2"
  type: "Power"
  bottom: "torque_weight"
  top: "torque_weight^2"
  power_param {
    power: 2
  }
}
layer {
  name: "eltwise_mult_torque"
  type: "Eltwise"
  bottom: "allU_reshape"
  bottom: "torque_weight^2"
  top: "all_torque"
  eltwise_param {
    operation: PROD
  }
}

layer {
  name: "add_torque_penalty"
  type: "Eltwise"
  bottom: "all_cost"
  bottom: "all_torque"
  top: "all_cost_withtorque"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 0.5  # torque/2 + cost
  }
}
layer {
  name: "demo_sample_slice"
  type: "Slice"
  bottom: "all_cost_withtorque"
  top: "demo_cost"
  top: "sample_cost"
  slice_param {
    axis: 0
    slice_point: 5 # Needs to be equal to demo batch size.
  }
}
layer {
  name: "loss"
  type: "IOCLoss"
  bottom: "demo_cost"
  bottom: "sample_cost"
  bottom: "dlogis"
  bottom: "slogis"
  top: "ioc_loss"
  loss_weight: 1.0 # Used 1 for most things, needs to be more for subsampled
}
