name: "JointAndImageStateRegressionNet"
layer {
  # Input is NxTxF
  name: "data_in_demos"
  type: "MemoryData"
  top: "cost_features"
  memory_data_param {
    input_shapes {
      dim: 1
      dim: 100  # T
      dim: 90  # 26+64
      dim: 1
    }
  }
  include: {phase:FORWARDB}
}
layer {
  name: "demo_img_data"
  type: "ImageData"
  top: "all_images"
  image_data_param {
    source: "img_database_temp/demo_ioc_images.txt"
    batch_size: 100  # Must be same as slice point and demo batch size*100
  }
  include: {phase: FORWARDA}
}

## START: FORWARDA NETWORK ##
# Image Processing Layers
layer {
  name: "conv1/7x7_s2"
  type: "Convolution"
  bottom: "all_images"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include: { phase: FORWARDA}
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  include: { phase: FORWARDA}
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include: { phase: FORWARDA}
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  include: { phase: FORWARDA}
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include: { phase: FORWARDA}
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  include: { phase: FORWARDA}
}
layer {
  name: "softmax"
  type: "SpatialSoftmax"
  bottom: "conv3"
  top: "conv3"
  spatial_softmax_param {
    engine: CAFFE
    temperature: 1.0
    dimension: "spatial"
  }
  include: { phase: FORWARDA}
}
layer {
  name: "fc_images"
  type: "InnerProduct"
  bottom: "conv3"
  top: "expected_xy"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2  # dimensionality will actually be 2*num_channels
    axis: -2
    weight_filler {
      type: "expectation"
      expectation_option: "xy"
      width: 109
      height: 109
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include: { phase: FORWARDA}
}
## END: FORWARDA NETWORK ##

## START: FORWARDB NETWORK ##
# Affine cost layer
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "cost_features"
  top: "Ax"
  param {
    lr_mult: 1 # 1 for full cold start
    decay_mult: 1
  }
  param {
    lr_mult: 2 # 2 for full cold start
    decay_mult: 0
  }
  inner_product_param {
    num_output: 26 # What should this be??
    axis: 2  # Input is NxTxF
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include: {phase:FORWARDB}
}

layer {
  name: "dotproduct1"
  type: "Eltwise"
  bottom: "Ax"
  bottom: "Ax"
  top: "2xcost"
  eltwise_param {
    operation: PROD
  }
  include: {phase:FORWARDB}
}
## END: FORWARDB NETWORK ##
